# ML_practice

Demonstrations of implementing an assorted collection of machine learning algorithms, with basic overviews/explanations of the algorithms. Emphasis is on familiarity with functions, so currently only implemented on [built-in data sets](https://scikit-learn.org/stable/datasets/real_world.html).

Algorithms written in [Jupyter Notebooks](https://jupyter.org/), implemented with [scikit-learn](https://scikit-learn.org/stable/).


### Complete List of Implmented Algorithms: ###

basic:
* Regression.ipynb: linear and logistic regression
* naiveBayes.ipynb: Naive Bayes
* SVN.ipynb: support vector machine
* kNN.ipynb: k-nearest neighbors
* Trees.ipynb: decision tree and random forest
* Clustering.ipynb: k-Means and DBScan
* XGBoost.ipynb: xgboost

deep_learning:
*

reinforcement_learning:
*

### To implement: ###
* Basic deep learning
	* DNN
	* CNN
	* RNN with LSTM
	* Transformers
* Specific deep learning
	* LeNet
	* AlexNet
	* VGG
	* ResNet
* Extra deep learning to consider demonstrating
	* GAN
	* Autoencoder


<! --
### Built-In Data Set Accuracy Tracker ###
Classification
* Iris: knn [1], naive Bayes [0.96], SVM [0.87], SVM (RBF) [1]
* Diabetes: decision tree [0.83]
* Wine: random forest [0.98]

Regression:
* Breast Cancer: logistic regression: 0.68, SVM [0.95]
-->