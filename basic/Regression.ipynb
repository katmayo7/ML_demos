{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Practice #\n",
    "\n",
    "The notebook is for practicing implementing linear and logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, feature_selection, preprocessing\n",
    "\n",
    "import sklearn.linear_model as linmodel\n",
    "import sklearn.metrics as smets\n",
    "\n",
    "#import statsmodels.api as stmod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression ##\n",
    "\n",
    "Linear regression estimales a linear relationship between a set of data point to minimize the distance between points and the classification line.\n",
    "\n",
    "Given a data set of n data points, ${x_{11}, \\dotsc, x_{np}}$, with $p$ \n",
    "features and set of labels ${y_1, \\dotsc, y_n}$.\n",
    "\n",
    "The model is:\n",
    "\n",
    "<center>$y_i = \\beta_0 + \\beta_1x_{11} + \\dotsc + \\beta_px_{np}$</center>\n",
    "\n",
    "With $\\beta_1, \\dotsc, \\beta_p$ called the coefficients and $\\beta_0$ called the intercept.\n",
    "\n",
    "The coefficients are fitted to the minimize the sum of square differences between the observed and predicted values.\n",
    "\n",
    "<center>$\\sum_{i=1} (y_i - \\hat{y}_i)^2$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Prcessing ####\n",
    "\n",
    "Import built-in diabetes data set from scikit-learn. The data set has 442 samples with 10 features. Split the data set into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes()\n",
    "X = data['data']\n",
    "Y = data['target']\n",
    "feature_names = data['feature_names']\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(X, Y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation ####\n",
    "\n",
    "Create a linear regression model using all features. \n",
    "Print model information including coefficients, intercept, and $R^2$ value.\n",
    "Evaluate using mean squared error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [  -22.26814641  -241.42457426   436.67850078   356.08475788\n",
      " -1217.1231068    731.7094332    307.02622289   263.88164544\n",
      "   941.51276238   113.56295229]\n",
      "Intercept: 154.07044007493036\n",
      "\n",
      "R-squared: 0.5236615315502134\n",
      "\n",
      "Mean squared error: 3030.2058457271664\n"
     ]
    }
   ],
   "source": [
    "model = linmodel.LinearRegression().fit(X_train, Y_train)\n",
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "print()\n",
    "rsq = model.score(X_train, Y_train)\n",
    "print('R-squared:', rsq)\n",
    "print()\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "mse = smets.mean_squared_error(Y_test, Y_pred)\n",
    "print('Mean squared error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering ####\n",
    "\n",
    "Implement feature selection using SelectKBest() with f_regression() functions to identify the value of each feature. Graph the results to visual which features are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# used to test the output of SelectKBest\n",
    "#f_st,p_val = feature_selection.f_regression(X_train, Y_train)\n",
    "#print(f_st)\n",
    "#print()\n",
    "#print(p_val)\n",
    "\n",
    "fit_model = feature_selection.SelectKBest(score_func=feature_selection.f_regression, k='all')\n",
    "fit_model.fit(X_train, Y_train)\n",
    "scores = fit_model.scores_\n",
    "\n",
    "x_ind = np.arange(len(scores))\n",
    "plt.bar(x_ind, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on results, it looks like the best feature is 2, while 8 is also useful. It seems like there are several other useful features, though 1, 5, and 4 are least useful. \n",
    "\n",
    "#### Model Creation with Feature Engineering ####\n",
    "\n",
    "As an arbitrary choice, I will assume adding features 2, 3, 6, 7, 8, 9 as possibly useful for model construction and worthwhile exploring. The number of features that should be used can be viewed as a hyperparameter which can be searched over. \n",
    "\n",
    "I will test constructing a model with features, in order of importance by f-statistic and find which offers the best performance on the training data as measured by mean-squared error. When adding a feature to the model, I will continue including the strategies that were deemed more important than it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features: [2, 8, 7, 3, 9]\n"
     ]
    }
   ],
   "source": [
    "# running with subsets of the data will probably be easiest by turning data into dataframe\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "\n",
    "features = [2, 8, 7, 3, 9, 6]\n",
    "best_sub = [] # best subset of features seen\n",
    "best_mse = math.inf # best mean_squared error seen\n",
    "\n",
    "for fi in range(1, len(features)):\n",
    "    # gather data for features\n",
    "    curr_feat = features[:fi]\n",
    "    sub_X = X_train_df[curr_feat]\n",
    "    if len(curr_feat) == 1:\n",
    "        sub_X = sub_X.to_numpy().reshape((-1, 1))\n",
    "        \n",
    "    # create model and test mse\n",
    "    sub_model = linmodel.LinearRegression().fit(sub_X, Y_train)\n",
    "    Y_pred = sub_model.predict(sub_X)\n",
    "    \n",
    "    mse = smets.mean_squared_error(Y_train, Y_pred)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_sub = curr_feat    \n",
    "\n",
    "print('Best features:', best_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show that a model with features 2, 3, 7, 8, and 9 demonstrate the best performance on the training data. This also shows my arbitrary choice of cut off point for which features to test was ok, since the wort feature was not deemed useful for the model.\n",
    "\n",
    "Next, I will construct a model using those features and compare results to the model with all features included when predicting the test set. Note, I could have just used output from the above feature search, but I wanted to separate out the different steps for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.47313327318464626\n",
      "Mean-squared error: 3003.9242041177\n"
     ]
    }
   ],
   "source": [
    "# make data sets use only necessary features\n",
    "feats = [2, 3, 7, 8, 9]\n",
    "new_X_train = X_train_df[feats]\n",
    "new_X_test = pd.DataFrame(X_test)\n",
    "new_X_test = new_X_test[feats]\n",
    "\n",
    "model = linmodel.LinearRegression().fit(new_X_train, Y_train)\n",
    "rsq = model.score(new_X_train, Y_train)\n",
    "print('R-squared:', rsq)\n",
    "\n",
    "Y_pred = model.predict(new_X_test)\n",
    "mse = smets.mean_squared_error(Y_test, Y_pred)\n",
    "print('Mean-squared error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations ###\n",
    "\n",
    "Model with all features:\n",
    "R^2: 0.523\n",
    "MSE: 3126.589\n",
    "\n",
    "Model with selective features:\n",
    "R^2: 0.483\n",
    "MSE: 3278.244\n",
    "\n",
    "Data shows that with feature selection, model performance on the test set actually degrades slightly (lower R^2 and a higher MSE). It may be that the feature selected model is overfitting slightly. This data set is rather small (train set has ~309 and testing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second example using the California Housing data set. ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "All features:\n",
      "--R-squared: 0.6070522363613844\n",
      "--MSE: 0.5287987809209836\n",
      "---------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "All features:\n",
      "--R-squared: 0.47786963577496133\n",
      "--MSE: 0.7165600593210025\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# test the above using a different data set\n",
    "data = datasets.fetch_california_housing(as_frame=True)\n",
    "fnames = data['feature_names']\n",
    "X = data['data']\n",
    "Y = data['target']\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(X, Y, train_size=0.7)\n",
    "\n",
    "# construct model with all data\n",
    "model = linmodel.LinearRegression().fit(X_train, Y_train)\n",
    "rsq = model.score(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "mse = smets.mean_squared_error(Y_test, Y_pred)\n",
    "print('---------------------------')\n",
    "print('All features:')\n",
    "print('--R-squared:', rsq)\n",
    "print('--MSE:', mse)\n",
    "print('---------------------------')\n",
    "\n",
    "# perform feature selection\n",
    "fmodel = feature_selection.SelectKBest(score_func=feature_selection.f_regression, k='all')\n",
    "fmodel.fit(X_train, Y_train)\n",
    "scores = fmodel.scores_\n",
    "\n",
    "plt.bar(fnames, scores)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# create model using top features\n",
    "new_X_train = X_train[['MedInc']]\n",
    "new_X_test = X_test[['MedInc']]\n",
    "\n",
    "model = linmodel.LinearRegression().fit(new_X_train, Y_train)\n",
    "rsq = model.score(new_X_train, Y_train)\n",
    "Y_pred = model.predict(new_X_test)\n",
    "mse = smets.mean_squared_error(Y_test, Y_pred)\n",
    "print('---------------------------')\n",
    "print('All features:')\n",
    "print('--R-squared:', rsq)\n",
    "print('--MSE:', mse)\n",
    "print('---------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly finding that feature selection is showing slightly degraded performance. Think in both cases, while there's not as much information coming from the other features, they are still signaling something of use for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression ##\n",
    "\n",
    "Logistics regression uses the linear regression model to a classification task. The output from the linear regression model, $\\hat{y}$, is used to calculate the probability of belonging to class 0 or 1 using the sigmoid function.\n",
    "\n",
    "<center>$p(\\hat{y}' = 0) = \\frac{1}{1-e^{-\\hat{y}}}$</center>\n",
    "<center>$p(\\hat{y}' = 1) = 1 - p(\\hat{y})$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing ####\n",
    "\n",
    "Import the scikit-learn built-in cancer data set, which as 2 classes (Maignant: 212 samples and Benign: 357 samples). There are 30 features. The data is partitioned into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "X = data['data']\n",
    "Y = data['target']\n",
    "fnames = data['feature_names']\n",
    "print('Features:', fnames)\n",
    "\n",
    "# apply normalization to fix logistic regression over stopping iterations\n",
    "X = preprocessing.Normalizer().fit_transform(X, Y)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(X, Y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a logistic regression model using all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6842105263157895\n",
      "Precision: 0.6447368421052632\n",
      "Recall: 1.0\n",
      "F1 score: 0.7839999999999999\n"
     ]
    }
   ],
   "source": [
    "model = linmodel.LogisticRegression(max_iter=100).fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "acc = model.score(X_test, Y_test)\n",
    "print('Accuracy:', acc)\n",
    "prec = smets.precision_score(Y_test, Y_pred)\n",
    "print('Precision:', prec)\n",
    "recall = smets.recall_score(Y_test, Y_pred)\n",
    "print('Recall:', recall)\n",
    "f1 = smets.f1_score(Y_test, Y_pred)\n",
    "print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis ####\n",
    "\n",
    "The recall results show the model is very good at identifying the truely malignant cases. However, the precision results show there are a handful of benign cases that have erronously been labeled as malignant. These results are reflected in the F1 score as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Logistic Regression Note ####\n",
    "\n",
    "This examples is a binary case. However, logistic regression can also be used for $K > 2$ classes. In this case, $K$ binary logistic regression models are created and a softmax function is used instead to calculate the probability of belonging to a given class, $k$.\n",
    "\n",
    "<center>$p(\\hat{y}' = k) = \\frac{e^{\\hat{y}_k}}{1 + \\sum_{j=1}^{K} e^{\\hat{y}_j}}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
