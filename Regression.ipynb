{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Practice #\n",
    "\n",
    "The notebook is for practicing implementing linear and logistic regression models. The emphassis is on best implementation practices, so only uses built-in data sets for ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, feature_selection\n",
    "\n",
    "import sklearn.linear_model as linmodel\n",
    "import sklearn.metrics as smets\n",
    "\n",
    "#import statsmodels.api as stmod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression ##\n",
    "\n",
    "Import built-in diabetes data set from scikit-learn. Data set has 442 samples with 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes()\n",
    "X = data['data']\n",
    "Y = data['target']\n",
    "feature_names = data['feature_names']\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(X, Y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a linear regression model using all features. \n",
    "Print model information including coefficients, intercept, and R^2 value.\n",
    "Evaluate using mean squared error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [  -25.01078169  -279.20524608   510.68685703   388.68716374\n",
      " -1055.31561314   740.56169511   183.64953058   143.740268\n",
      "   869.36020183   140.38821777]\n",
      "Intercept: 151.72158943452115\n",
      "R-squared: 0.5330263073376078\n",
      "\n",
      "Mean squared error: 2770.2575755872604\n"
     ]
    }
   ],
   "source": [
    "model = linmodel.LinearRegression().fit(X_train, Y_train)\n",
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "rsq = model.score(X_train, Y_train)\n",
    "print('R-squared:', rsq)\n",
    "print()\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "mse = smets.mean_squared_error(Y_test, Y_pred)\n",
    "print('Mean squared error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement feature selection using SelectKBest() with f_regression() functions to identify the value of each feature. Graph the results to visual which features are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# used to test the output of SelectKBest\n",
    "#f_st,p_val = feature_selection.f_regression(X_train, Y_train)\n",
    "#print(f_st)\n",
    "#print()\n",
    "#print(p_val)\n",
    "\n",
    "fit_model = feature_selection.SelectKBest(score_func=feature_selection.f_regression, k='all')\n",
    "fit_model.fit(X_train, Y_train)\n",
    "scores = fit_model.scores_\n",
    "\n",
    "x_ind = np.arange(len(scores))\n",
    "plt.bar(x_ind, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on results, it looks like the best feature is 2, while 8 is also useful. It seems like there are several other useful features, though 1, 5, and 4 are least useful. \n",
    "\n",
    "As an arbitrary choice, I will assume adding features 2, 3, 6, 7, 8, 9 as possibly useful for model construction and worthwhile exploring. The number of features that should be used can be viewed as a hyperparameter which can be searched over. \n",
    "\n",
    "I will test constructing a model with features, in order of importance by f-statistic and find which offers the best performance on the training data as measured by mean-squared error. When adding a feature to the model, I will continue including the strategies that were deemed more important than it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features: [2, 8, 3, 9, 7]\n"
     ]
    }
   ],
   "source": [
    "# running with subsets of the data will probably be easiest by turning data into dataframe\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "\n",
    "features = [2, 8, 3, 9, 7, 6]\n",
    "best_sub = [] # best subset of features seen\n",
    "best_mse = math.inf # best mean_squared error seen\n",
    "\n",
    "for fi in range(1, len(features)):\n",
    "    # gather data for features\n",
    "    curr_feat = features[:fi]\n",
    "    sub_X = X_train_df[curr_feat]\n",
    "    if len(curr_feat) == 1:\n",
    "        sub_X = sub_X.to_numpy().reshape((-1, 1))\n",
    "        \n",
    "    # create model and test mse\n",
    "    sub_model = linmodel.LinearRegression().fit(sub_X, Y_train)\n",
    "    Y_pred = sub_model.predict(sub_X)\n",
    "    \n",
    "    mse = smets.mean_squared_error(Y_train, Y_pred)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_sub = curr_feat    \n",
    "\n",
    "print('Best features:', best_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show that a model with features 2, 3, 7, 8, and 9 demonstrate the best performance on the training data. This also shows my arbitrary choice of cut off point for which features to test was ok, since the wort feature was not deemed useful for the model.\n",
    "\n",
    "Next, I will construct a model using those features and compare results to the model with all features included when predicting the test set. Note, I could have just used output from the above feature search, but I wanted to separate out the different steps for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.4947715182604221\n",
      "Mean-squared error: 2904.4045639031838\n"
     ]
    }
   ],
   "source": [
    "# make data sets use only necessary features\n",
    "feats = [2, 3, 8, 7, 9]\n",
    "new_X_train = X_train_df[feats]\n",
    "new_X_test = pd.DataFrame(X_test)\n",
    "new_X_test = new_X_test[feats]\n",
    "\n",
    "model = linmodel.LinearRegression().fit(new_X_train, Y_train)\n",
    "rsq = model.score(new_X_train, Y_train)\n",
    "print('R-squared:', rsq)\n",
    "\n",
    "Y_pred = model.predict(new_X_test)\n",
    "mse = smets.mean_squared_error(Y_test, Y_pred)\n",
    "print('Mean-squared error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations ###\n",
    "\n",
    "Model with all features:\n",
    "R^2: 0.533\n",
    "MSE: 2770.258\n",
    "\n",
    "Model with selective features:\n",
    "R^2: 0.495\n",
    "MSE: 2904.405\n",
    "\n",
    "Data shows that with feature selection, model performance on the test set actually degrades slightly (lower R^2 and a higher MSE). It may be that the feature selected model is overfitting slightly. This data set is rather small (train set has ~309 and testing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
